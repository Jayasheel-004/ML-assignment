{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff6a09c",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 30px; font-weight: bold; text-align: center;\">\n",
    "  ASSIGNMENT-2\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea37163",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\" font-size:25px; font-weight:bold \">Q1</h1>\n",
    "\n",
    "<h1 style=\" font-size:20px; font-weight:bold \">(a)</h1>\n",
    "Examine the values of each attribute and Select a set of attributes only that would affect to predict future bike buyers to create your input for data mining algorithms. Remove all the unnecessary attributes. (Select features just by analysis). \n",
    "\n",
    "<h1 style=\" font-size:20px; font-weight:bold \">(b)</h1>\n",
    "Create a new Data Frame with the selected attributes only. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9823c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Title         City    StateProvinceName CountryRegionName PostalCode  \\\n",
      "0   NaN   Wollongong      New South Wales         Australia       2500   \n",
      "1   NaN      Shawnee     British Columbia            Canada    V9B 2C3   \n",
      "2   NaN  West Covina           California     United States      91791   \n",
      "3   NaN    Liverpool              England    United Kingdom     L4 4HB   \n",
      "4   NaN        Werne  Nordrhein-Westfalen           Germany      59368   \n",
      "\n",
      "    BirthDate        Education      Occupation Gender MaritalStatus  \\\n",
      "0  1987-11-13        Bachelors        Clerical      M             M   \n",
      "1  1972-07-21  Partial College        Clerical      M             M   \n",
      "2  1985-11-09        Bachelors        Clerical      F             S   \n",
      "3  1977-10-18  Partial College  Skilled Manual      M             M   \n",
      "4  1975-02-05  Partial College  Skilled Manual      M             S   \n",
      "\n",
      "   HomeOwnerFlag  NumberCarsOwned  NumberChildrenAtHome  TotalChildren  \\\n",
      "0              1                3                     0              1   \n",
      "1              1                2                     1              2   \n",
      "2              0                3                     0              0   \n",
      "3              1                2                     1              2   \n",
      "4              1                1                     0              0   \n",
      "\n",
      "   YearlyIncome  \n",
      "0         81916  \n",
      "1         81076  \n",
      "2         86387  \n",
      "3         61481  \n",
      "4         51804  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"AWCustomers.csv\")\n",
    "\n",
    "selected_cols = [\n",
    "    'Title', 'City', 'StateProvinceName', 'CountryRegionName', 'PostalCode',\n",
    "    'BirthDate', 'Education', 'Occupation', 'Gender', 'MaritalStatus',\n",
    "    'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome'\n",
    "]\n",
    "df_selected = df[selected_cols].copy()\n",
    "\n",
    "print(df_selected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf33556",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:20px; font-weight:bold \">(c)</h1>  Determine a Data value type (Discrete, or Continuous, then Nominal, Ordinal, Interval, Ratio) of \n",
    "each attribute in your selection to identify preprocessing tasks to create input for your data mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abad06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Value Type = Discrete, Scale = Nominal\n",
      "City: Value Type = Discrete, Scale = Nominal\n",
      "StateProvinceName: Value Type = Discrete, Scale = Nominal\n",
      "CountryRegionName: Value Type = Discrete, Scale = Nominal\n",
      "PostalCode: Value Type = Discrete, Scale = Nominal\n",
      "BirthDate: Value Type = Continuous, Scale = Interval\n",
      "Education: Value Type = Discrete, Scale = Ordinal\n",
      "Occupation: Value Type = Discrete, Scale = Nominal\n",
      "Gender: Value Type = Discrete, Scale = Nominal\n",
      "MaritalStatus: Value Type = Discrete, Scale = Nominal\n",
      "HomeOwnerFlag: Value Type = Discrete, Scale = Nominal\n",
      "NumberCarsOwned: Value Type = Discrete, Scale = Ratio\n",
      "NumberChildrenAtHome: Value Type = Discrete, Scale = Ratio\n",
      "TotalChildren: Value Type = Discrete, Scale = Ratio\n",
      "YearlyIncome: Value Type = Continuous, Scale = Ratio\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_types = {\n",
    "    'Title': ('Discrete', 'Nominal'),\n",
    "    'City': ('Discrete', 'Nominal'),\n",
    "    'StateProvinceName': ('Discrete', 'Nominal'),\n",
    "    'CountryRegionName': ('Discrete', 'Nominal'),\n",
    "    'PostalCode': ('Discrete', 'Nominal'),\n",
    "    'BirthDate': ('Continuous', 'Interval'),  \n",
    "    'Education': ('Discrete', 'Ordinal'),     \n",
    "    'Occupation': ('Discrete', 'Nominal'),\n",
    "    'Gender': ('Discrete', 'Nominal'),\n",
    "    'MaritalStatus': ('Discrete', 'Nominal'),\n",
    "    'HomeOwnerFlag': ('Discrete', 'Nominal'),  \n",
    "    'NumberCarsOwned': ('Discrete', 'Ratio'),\n",
    "    'NumberChildrenAtHome': ('Discrete', 'Ratio'),\n",
    "    'TotalChildren': ('Discrete', 'Ratio'),\n",
    "    'YearlyIncome': ('Continuous', 'Ratio'),\n",
    "}\n",
    "\n",
    "for col, (value_type, scale) in data_types.items():\n",
    "    print(f\"{col}: Value Type = {value_type}, Scale = {scale}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cebcc5",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:25px; font-weight:bold \">Q2</h1>\n",
    "\n",
    "\n",
    "Depending on the data type of each attribute, transform each object from your preprocessed data.  \n",
    "Use all the data rows (~= 18000 rows) with the selected features as input to apply all the tasks below, do \n",
    "not perform each task on the smaller data set that you got from your random sampling result.  \n",
    "\n",
    "<h1 style=\" font-size:20px; font-weight:bold \">(a)</h1>\n",
    "Handling Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f59c4f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values handled\n",
      "Title                   0\n",
      "City                    0\n",
      "StateProvinceName       0\n",
      "CountryRegionName       0\n",
      "PostalCode              0\n",
      "BirthDate               0\n",
      "Education               0\n",
      "Occupation              0\n",
      "Gender                  0\n",
      "MaritalStatus           0\n",
      "HomeOwnerFlag           0\n",
      "NumberCarsOwned         0\n",
      "NumberChildrenAtHome    0\n",
      "TotalChildren           0\n",
      "YearlyIncome            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_1920\\1129448.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_selected['BirthDate'].fillna(median_birthdate, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"AWCustomers.csv\")\n",
    "\n",
    "# Selected columns as per Part I\n",
    "selected_cols = [\n",
    "    'Title', 'City', 'StateProvinceName', 'CountryRegionName', 'PostalCode',\n",
    "    'BirthDate', 'Education', 'Occupation', 'Gender', 'MaritalStatus',\n",
    "    'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren',\n",
    "    'YearlyIncome'\n",
    "]\n",
    "\n",
    "df_selected = df[selected_cols].copy()\n",
    "\n",
    "# Convert BirthDate to datetime\n",
    "df_selected['BirthDate'] = pd.to_datetime(df_selected['BirthDate'], errors='coerce')\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_cols = ['NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome']\n",
    "categorical_cols = list(set(selected_cols) - set(numeric_cols) - {'BirthDate'})\n",
    "\n",
    "# Impute numeric columns with median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df_selected[numeric_cols] = num_imputer.fit_transform(df_selected[numeric_cols])\n",
    "\n",
    "# Impute categorical columns with mode\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_selected[categorical_cols] = cat_imputer.fit_transform(df_selected[categorical_cols])\n",
    "\n",
    "# Impute BirthDate with median date\n",
    "median_birthdate = df_selected['BirthDate'].median()\n",
    "df_selected['BirthDate'].fillna(median_birthdate, inplace=True)\n",
    "\n",
    "print(\"Null values handled\")\n",
    "print(df_selected.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0b170",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:20px; font-weight:bold \">(b)</h1> Normalization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b75f558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization applied to numeric columns:\n",
      "   NumberCarsOwned  NumberChildrenAtHome  TotalChildren  YearlyIncome\n",
      "0              0.6              0.000000       0.333333      0.496842\n",
      "1              0.4              0.333333       0.666667      0.489453\n",
      "2              0.6              0.000000       0.000000      0.536172\n",
      "3              0.4              0.333333       0.666667      0.317083\n",
      "4              0.2              0.000000       0.000000      0.231958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select numeric columns for normalization\n",
    "numeric_cols = ['NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome']\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply normalization\n",
    "df_selected[numeric_cols] = scaler.fit_transform(df_selected[numeric_cols])\n",
    "\n",
    "print(\"Normalization applied to numeric columns:\")\n",
    "print(df_selected[numeric_cols].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5525d30",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:20px; font-weight:bold \">(c)</h1> Discretization (Binning) on Continuous attributes or Categorical Attributes with too many different \n",
    "values  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "410fd023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binned 'YearlyIncome' into categories:\n",
      "   YearlyIncome  YearlyIncome_Binned\n",
      "0      0.496842                    1\n",
      "1      0.489453                    1\n",
      "2      0.536172                    2\n",
      "3      0.317083                    1\n",
      "4      0.231958                    0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bins = 4\n",
    "df_selected['YearlyIncome_Binned'] = pd.cut(df_selected['YearlyIncome'], bins=bins, labels=False)\n",
    "\n",
    "print(\"Binned 'YearlyIncome' into categories:\")\n",
    "print(df_selected[['YearlyIncome', 'YearlyIncome_Binned']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90247c17",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:20px; font-weight:bold \">(d)</h1>Standardization/Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d523c35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized numerical columns:\n",
      "   YearlyIncome  NumberCarsOwned  TotalChildren\n",
      "0      0.298555         1.892524       0.161342\n",
      "1      0.271180         0.798389       1.239753\n",
      "2      0.444261         1.892524      -0.917069\n",
      "3     -0.367401         0.798389       1.239753\n",
      "4     -0.682765        -0.295746      -0.917069\n",
      "\n",
      "Normalized numerical columns:\n",
      "   YearlyIncome  NumberCarsOwned  TotalChildren\n",
      "0      0.496842              0.6       0.333333\n",
      "1      0.489453              0.4       0.666667\n",
      "2      0.536172              0.6       0.000000\n",
      "3      0.317083              0.4       0.666667\n",
      "4      0.231958              0.2       0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Initialize scalers\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Select numerical columns for scaling\n",
    "num_cols = ['YearlyIncome', 'NumberCarsOwned', 'TotalChildren']\n",
    "\n",
    "# Standardization (mean=0, std=1)\n",
    "df_selected_std = df_selected.copy()\n",
    "df_selected_std[num_cols] = standard_scaler.fit_transform(df_selected[num_cols])\n",
    "print(\"Standardized numerical columns:\")\n",
    "print(df_selected_std[num_cols].head())\n",
    "\n",
    "# Normalization (scale to [0,1])\n",
    "df_selected_norm = df_selected.copy()\n",
    "df_selected_norm[num_cols] = minmax_scaler.fit_transform(df_selected[num_cols])\n",
    "print(\"\\nNormalized numerical columns:\")\n",
    "print(df_selected_norm[num_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b96049",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:20px; font-weight:bold \">(e)</h1> Binarization (One Hot Encoding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a8d5c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding complete. Transformed DataFrame:\n",
      "   BirthDate  NumberCarsOwned  NumberChildrenAtHome  TotalChildren  \\\n",
      "0 1987-11-13              0.6              0.000000       0.333333   \n",
      "1 1972-07-21              0.4              0.333333       0.666667   \n",
      "2 1985-11-09              0.6              0.000000       0.000000   \n",
      "3 1977-10-18              0.4              0.333333       0.666667   \n",
      "4 1975-02-05              0.2              0.000000       0.000000   \n",
      "\n",
      "   YearlyIncome  YearlyIncome_Binned  Title_Mrs.  Title_Ms  Title_Ms.  \\\n",
      "0      0.496842                    1         0.0       0.0        0.0   \n",
      "1      0.489453                    1         0.0       0.0        0.0   \n",
      "2      0.536172                    2         0.0       0.0        0.0   \n",
      "3      0.317083                    1         0.0       0.0        0.0   \n",
      "4      0.231958                    0         0.0       0.0        0.0   \n",
      "\n",
      "   Title_Sr.  ...  Education_High School  Education_Partial College  \\\n",
      "0        0.0  ...                    0.0                        0.0   \n",
      "1        0.0  ...                    0.0                        1.0   \n",
      "2        0.0  ...                    0.0                        0.0   \n",
      "3        0.0  ...                    0.0                        1.0   \n",
      "4        0.0  ...                    0.0                        1.0   \n",
      "\n",
      "   Education_Partial High School  Occupation_Management  Occupation_Manual  \\\n",
      "0                            0.0                    0.0                0.0   \n",
      "1                            0.0                    0.0                0.0   \n",
      "2                            0.0                    0.0                0.0   \n",
      "3                            0.0                    0.0                0.0   \n",
      "4                            0.0                    0.0                0.0   \n",
      "\n",
      "   Occupation_Professional  Occupation_Skilled Manual  Gender_M  \\\n",
      "0                      0.0                        0.0       1.0   \n",
      "1                      0.0                        0.0       1.0   \n",
      "2                      0.0                        0.0       0.0   \n",
      "3                      0.0                        1.0       1.0   \n",
      "4                      0.0                        1.0       1.0   \n",
      "\n",
      "   MaritalStatus_S  HomeOwnerFlag_1  \n",
      "0              0.0              1.0  \n",
      "1              0.0              1.0  \n",
      "2              1.0              0.0  \n",
      "3              0.0              1.0  \n",
      "4              1.0              1.0  \n",
      "\n",
      "[5 rows x 669 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_cols = [\n",
    "    'Title', 'City', 'StateProvinceName', 'CountryRegionName', 'PostalCode',\n",
    "    'Education', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag'\n",
    "]\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder =OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit and transform\n",
    "encoded_array = encoder.fit_transform(df_selected[categorical_cols])\n",
    "\n",
    "# Get column names\n",
    "encoded_col_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Create DataFrame from encoded data\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoded_col_names)\n",
    "\n",
    "# Reset index to align with df_selected\n",
    "encoded_df.index = df_selected.index\n",
    "\n",
    "# Drop original categorical columns and concatenate the encoded columns\n",
    "df_encoded = pd.concat([df_selected.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "\n",
    "print(\"One-hot encoding complete. Transformed DataFrame:\")\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb127969",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:25px; font-weight:bold \">Q3</h1>\n",
    "\n",
    "Make sure each attribute is transformed in a same scale for numeric attributes and Binarization for each \n",
    "nominal attribute, and each discretized numeric attribute to standardization. Make sure to apply a correct \n",
    "similarity measure for nominal (one hot encoding)/binary attributes and numeric attributes respectively. \n",
    "\n",
    "<h1 style=\" font-size:20px; font-weight:bold \">(a)</h1> Calculate Similarity in Simple Matching, Jaccard Similarity, and Cosine Similarity between two \n",
    "following objects of your transformed input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d84ad93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Measures Between Object 0 and 1\n",
      "Simple Matching Coefficient (SMC): 0.9109\n",
      "Jaccard Similarity (Categorical): 0.1111\n",
      "Cosine Similarity (All Features): 0.1893\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import jaccard\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"AWCustomers.csv\")\n",
    "\n",
    "# Step 2: Select relevant columns (including CommuteDistance if needed later)\n",
    "selected_cols = [\n",
    "    'Title', 'City', 'StateProvinceName', 'CountryRegionName', 'PostalCode',\n",
    "    'BirthDate', 'Education', 'Occupation', 'Gender', 'MaritalStatus',\n",
    "    'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome',\n",
    "    'TotalChildren', 'YearlyIncome'\n",
    "]\n",
    "\n",
    "df_selected = df[selected_cols].copy()\n",
    "\n",
    "# Step 3: Drop rows with missing values for simplicity\n",
    "df_cleaned = df_selected.dropna().reset_index(drop=True)\n",
    "\n",
    "# Step 4: Define numeric and categorical columns\n",
    "numeric_cols = ['NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome']\n",
    "categorical_cols = ['Title', 'City', 'StateProvinceName', 'CountryRegionName', 'PostalCode',\n",
    "                    'Education', 'Occupation', 'Gender', 'MaritalStatus', 'HomeOwnerFlag']\n",
    "\n",
    "# Step 5: Standardize numeric data\n",
    "scaler = StandardScaler()\n",
    "numeric_scaled = scaler.fit_transform(df_cleaned[numeric_cols])\n",
    "numeric_df = pd.DataFrame(numeric_scaled, columns=numeric_cols)\n",
    "\n",
    "# Step 6: One-hot encode categorical data\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "categorical_encoded = encoder.fit_transform(df_cleaned[categorical_cols])\n",
    "categorical_df = pd.DataFrame(categorical_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Step 7: Combine transformed features\n",
    "df_transformed = pd.concat([numeric_df, categorical_df], axis=1)\n",
    "\n",
    "# Step 8: Choose two objects (first two rows)\n",
    "obj1 = df_transformed.iloc[0]\n",
    "obj2 = df_transformed.iloc[1]\n",
    "\n",
    "# --- Similarity Metrics ---\n",
    "\n",
    "# Simple Matching Coefficient\n",
    "def simple_matching(a, b):\n",
    "    matches = np.sum(a == b)\n",
    "    return matches / len(a)\n",
    "\n",
    "# Jaccard Similarity - on categorical (binary) attributes only\n",
    "cat_obj1 = categorical_df.iloc[0].astype(bool)\n",
    "cat_obj2 = categorical_df.iloc[1].astype(bool)\n",
    "\n",
    "# Cosine Similarity - on full transformed feature vector\n",
    "cos_sim = cosine_similarity([obj1], [obj2])[0][0]\n",
    "\n",
    "# Results\n",
    "smc = simple_matching(obj1, obj2)\n",
    "jaccard_sim = 1 - jaccard(cat_obj1, cat_obj2)\n",
    "\n",
    "print(\"Similarity Measures Between Object 0 and 1\")\n",
    "print(f\"Simple Matching Coefficient (SMC): {smc:.4f}\")\n",
    "print(f\"Jaccard Similarity (Categorical): {jaccard_sim:.4f}\")\n",
    "print(f\"Cosine Similarity (All Features): {cos_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940a3e9",
   "metadata": {},
   "source": [
    "<h1 style=\" font-size:20px; font-weight:bold \">(b)</h1> Calculate Correlation between two features Commute Distance and Yearly Income"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
