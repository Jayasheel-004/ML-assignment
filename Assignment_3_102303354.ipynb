{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cea302b",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 30px; font-weight: bold; text-align: center;\">\n",
    "  ASSIGNMENT-3\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a0649",
   "metadata": {},
   "source": [
    "**Q1-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58129d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
      "0       79545.45857             5.682861                   7.009188   \n",
      "1       79248.64245             6.002900                   6.730821   \n",
      "2       61287.06718             5.865890                   8.512727   \n",
      "3       63345.24005             7.188236                   5.586729   \n",
      "4       59982.19723             5.040555                   7.839388   \n",
      "\n",
      "   Avg. Area Number of Bedrooms  Area Population         Price  \n",
      "0                          4.09      23086.80050  1.059034e+06  \n",
      "1                          3.09      40173.07217  1.505891e+06  \n",
      "2                          5.13      36882.15940  1.058988e+06  \n",
      "3                          3.26      34310.24283  1.260617e+06  \n",
      "4                          4.23      26354.10947  6.309435e+05  \n",
      "Index(['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n",
      "       'Avg. Area Number of Bedrooms', 'Area Population', 'Price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"USA_Housing.csv\")\n",
    "\n",
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e350b972",
   "metadata": {},
   "source": [
    "(A)  \n",
    "Divide the dataset into input features (all columns except price) and output variable  \n",
    "(price)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e18dffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population', 'Price']\n",
      "Shape of X (features): (5000, 5)\n",
      "Shape of y (target): (5000,)\n",
      "\n",
      "First 5 rows of X:\n",
      " [[7.95454586e+04 5.68286132e+00 7.00918814e+00 4.09000000e+00\n",
      "  2.30868005e+04]\n",
      " [7.92486424e+04 6.00289981e+00 6.73082102e+00 3.09000000e+00\n",
      "  4.01730722e+04]\n",
      " [6.12870672e+04 5.86588984e+00 8.51272743e+00 5.13000000e+00\n",
      "  3.68821594e+04]\n",
      " [6.33452401e+04 7.18823609e+00 5.58672866e+00 3.26000000e+00\n",
      "  3.43102428e+04]\n",
      " [5.99821972e+04 5.04055452e+00 7.83938779e+00 4.23000000e+00\n",
      "  2.63541095e+04]]\n",
      "\n",
      "First 5 values of y:\n",
      " [1059033.558  1505890.915  1058987.988  1260616.807   630943.4893]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['Price']).values\n",
    "y = data['Price'].values\n",
    "\n",
    "print(\"Columns in dataset:\", data.columns.tolist())\n",
    "print(\"Shape of X (features):\", X.shape)\n",
    "print(\"Shape of y (target):\", y.shape)\n",
    "\n",
    "print(\"\\nFirst 5 rows of X:\\n\", X[:5])\n",
    "print(\"\\nFirst 5 values of y:\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5416187",
   "metadata": {},
   "source": [
    "(B)            \n",
    "Scale the values of input features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d244b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled feature sample (first 5 rows):\n",
      " [[ 1.02865969 -0.29692705  0.02127433  0.08806222 -1.31759867]\n",
      " [ 1.00080775  0.02590164 -0.25550611 -0.72230146  0.40399945]\n",
      " [-0.68462915 -0.11230283  1.5162435   0.93084045  0.07240989]\n",
      " [-0.49149907  1.22157207 -1.39307717 -0.58453963 -0.18673422]\n",
      " [-0.80707253 -0.94483368  0.84674187  0.20151314 -0.98838741]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Scaled feature sample (first 5 rows):\\n\", X_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d541982",
   "metadata": {},
   "source": [
    "(C)    \n",
    "  Divide input and output features into five folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bdd66b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 1000 samples\n",
      "Fold 2: 1000 samples\n",
      "Fold 3: 1000 samples\n",
      "Fold 4: 1000 samples\n",
      "Fold 5: 1000 samples\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(X_scaled))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "folds = np.array_split(indices, 5)\n",
    "\n",
    "for i, fold in enumerate(folds, 1):\n",
    "    print(f\"Fold {i}: {len(fold)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba41e0",
   "metadata": {},
   "source": [
    "(D)        \n",
    "Run five iterations, in each iteration consider one-fold as test set and remaining \n",
    "four sets as training set. Find the beta (ùõΩ) matrix, predicted values, and R2_score \n",
    "for each iteration using least square error fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94cc62b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Beta coefficients:\n",
      " [1232295.41431078  229295.12169885  164774.17723437  121347.25062335\n",
      "    2241.76878869  150950.28318239]\n",
      "R2_score: 0.915624774854771 \n",
      "\n",
      "Iteration 2\n",
      "Beta coefficients:\n",
      " [1232039.87990824  229487.55387449  163335.50973855  121214.889636\n",
      "    1362.87280849  150277.12327973]\n",
      "R2_score: 0.9236454644383387 \n",
      "\n",
      "Iteration 3\n",
      "Beta coefficients:\n",
      " [1233373.28485355  229869.76935062  165108.61630722  122309.70562153\n",
      "    1969.76228957  152068.11025107]\n",
      "R2_score: 0.916609354085722 \n",
      "\n",
      "Iteration 4\n",
      "Beta coefficients:\n",
      " [1231315.59164667  230097.72334034  163930.10813771  120963.88451255\n",
      "    2530.80066234  150536.3166272 ]\n",
      "R2_score: 0.9153963244889614 \n",
      "\n",
      "Iteration 5\n",
      "Beta coefficients:\n",
      " [1231354.1912127   231011.79652308  163850.56819392  120939.73271902\n",
      "    2091.86932031  150498.2983476 ]\n",
      "R2_score: 0.917134125375134 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "beta_list = []  \n",
    "r2_s = []   \n",
    "\n",
    "for i in range(5):\n",
    "    test_idx = folds[i]\n",
    "    X_test, y_test = X_scaled[test_idx], y[test_idx]\n",
    "    train_idx = np.concatenate([folds[j] for j in range(5) if j!=i])\n",
    "    X_train, y_train = X_scaled[train_idx], y[train_idx]\n",
    "\n",
    "    X_train_bias = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "    X_test_bias  = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "\n",
    "    beta = np.linalg.inv(X_train_bias.T@X_train_bias)@(X_train_bias.T @ y_train)\n",
    "\n",
    "    y_pred=X_test_bias @ beta\n",
    "    score=r2_score(y_test, y_pred)\n",
    "\n",
    "    beta_list.append(beta)\n",
    "    r2_s.append(score)\n",
    "\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    print(\"Beta coefficients:\\n\", beta)\n",
    "    print(\"R2_score:\", score, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91cab5",
   "metadata": {},
   "source": [
    "(E)          \n",
    "Use the best value of (ùõΩ) matrix (for which R2_score is maximum), to train the \n",
    "regressor for 70% of data and test the performance for remaining 30% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1782216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "b R2_score from cross-validation: 0.9236454644383387\n",
      "b Beta coefficients:\n",
      " [1232039.87990824  229487.55387449  163335.50973855  121214.889636\n",
      "    1362.87280849  150277.12327973]\n",
      "\n",
      "Final model evaluation on 30% test set\n",
      "Final Beta coefficients:\n",
      " [1233516.27706963  231026.50499134  164126.40645338  121120.90089886\n",
      "    1310.72742428  150279.13642153]\n",
      "Final R2_score: 0.9176499755975894\n"
     ]
    }
   ],
   "source": [
    "b_index = np.argmax(r2_s)\n",
    "b_beta = beta_list[b_index]\n",
    "\n",
    "print(\"\\nb R2_score from cross-validation:\", r2_s[b_index])\n",
    "print(\"b Beta coefficients:\\n\", b_beta)\n",
    "\n",
    "split = int(0.7 * len(X_scaled))\n",
    "X_train, y_train = X_scaled[:split], y[:split]\n",
    "X_test, y_test = X_scaled[split:], y[split:]\n",
    "\n",
    "X_train_bias = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "X_test_bias  = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "\n",
    "final_beta = np.linalg.inv(X_train_bias.T @ X_train_bias) @ (X_train_bias.T @ y_train)\n",
    "\n",
    "y_pred = X_test_bias @ final_beta\n",
    "\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nFinal model evaluation on 30% test set\")\n",
    "print(\"Final Beta coefficients:\\n\", final_beta)\n",
    "print(\"Final R2_score:\", final_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5cd320",
   "metadata": {},
   "source": [
    "**Q2-**           \n",
    "Concept of Validation set for Multiple Linear Regression (Gradient Descent  \n",
    "Optimization)  \n",
    "Consider the same dataset of Q1, rather than dividing the dataset into five folds, divide the \n",
    "dataset into training set (56%), validation set (14%), and test set (30%).  \n",
    "Consider four different values of learning rate i.e. {0.001,0.01,0.1,1}. Compute the values of \n",
    "regression coefficients for each value of learning rate after 1000 iterations.  \n",
    "For each set of regression coefficients, compute R2_score for validation and test set and find \n",
    "the best value of regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5b34670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR=0.001\n",
      "  Validation R2=-0.9353\n",
      "    Test R2=-0.8082\n",
      "LR=0.01\n",
      "  Validation R2=0.9151\n",
      "    Test R2=0.9175\n",
      "LR=0.1\n",
      "  Validation R2=0.9151\n",
      "    Test R2=0.9175\n",
      "LR=1\n",
      "  Validation R2=0.9151\n",
      "    Test R2=0.9175\n",
      "\n",
      "Best Learning Rate:    \n",
      "   0.1\n",
      "Best Validation R2:  \n",
      "   0.9151040123364315\n",
      "Corresponding Test R2:   \n",
      "   0.917477081644098\n",
      "Best Beta coefficients:  \n",
      "   [ 1.23244775e+06  2.31682635e+05  1.63635272e+05  1.19025219e+05\n",
      " -2.74956842e+02  1.50705906e+05]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"USA_Housing.csv\")\n",
    "\n",
    "X = data.drop(columns=['Price']).values\n",
    "y = data['Price'].values\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "n = len(X)\n",
    "train_end = int(0.56 * n)\n",
    "val_end   = int(0.70 * n)\n",
    "\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val     = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test, y_test   = X[val_end:], y[val_end:]\n",
    "\n",
    "def gradient_descent(X, y, lr, iters=1000):\n",
    "    m, n = X.shape\n",
    "    beta = np.zeros(n)\n",
    "    for _ in range(iters):\n",
    "        beta -= (lr/m) * (X.T @ (X @ beta - y))\n",
    "    return beta\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "best_beta, best_lr, best_val_r2, best_test_r2 = None, None, -1, None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    beta = gradient_descent(X_train, y_train, lr, iters=1000)\n",
    "\n",
    "    val_r2  = r2_score(y_val,  X_val @ beta)\n",
    "    test_r2 = r2_score(y_test, X_test @ beta)\n",
    "\n",
    "    print(f\"LR={lr}\\n  Validation R2={val_r2:.4f}\\n    Test R2={test_r2:.4f}\")\n",
    "\n",
    "    if val_r2 > best_val_r2:\n",
    "        best_beta, best_lr, best_val_r2, best_test_r2 = beta, lr, val_r2, test_r2\n",
    "\n",
    "# Final best results\n",
    "print(\"\\nBest Learning Rate:    \\n  \", best_lr)\n",
    "print(\"Best Validation R2:  \\n  \", best_val_r2)\n",
    "print(\"Corresponding Test R2:   \\n  \", best_test_r2)\n",
    "print(\"Best Beta coefficients:  \\n  \", best_beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116d0da",
   "metadata": {},
   "source": [
    "**Q3-**      \n",
    "1. Load the dataset with following column names [\"symboling\", \"normalized_losses\",  \n",
    "\"make\", \"fuel_type\", \"aspiration\",\"num_doors\", \"body_style\", \"drive_wheels\",  \n",
    "\"engine_location\", \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",  \n",
    "\"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\", \"bore\", \"stroke\",  \n",
    "\"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]  \n",
    "and replace all ? values with NaN  \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d94c88e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (205, 26)\n",
      "   symboling normalized_losses         make fuel_type aspiration num_doors  \\\n",
      "0          3               NaN  alfa-romero       gas        std       two   \n",
      "1          3               NaN  alfa-romero       gas        std       two   \n",
      "2          1               NaN  alfa-romero       gas        std       two   \n",
      "3          2               164         audi       gas        std      four   \n",
      "4          2               164         audi       gas        std      four   \n",
      "\n",
      "    body_style drive_wheels engine_location  wheel_base  ...  engine_size  \\\n",
      "0  convertible          rwd           front        88.6  ...          130   \n",
      "1  convertible          rwd           front        88.6  ...          130   \n",
      "2    hatchback          rwd           front        94.5  ...          152   \n",
      "3        sedan          fwd           front        99.8  ...          109   \n",
      "4        sedan          4wd           front        99.4  ...          136   \n",
      "\n",
      "   fuel_system  bore  stroke compression_ratio horsepower  peak_rpm city_mpg  \\\n",
      "0         mpfi  3.47    2.68               9.0        111      5000       21   \n",
      "1         mpfi  3.47    2.68               9.0        111      5000       21   \n",
      "2         mpfi  2.68    3.47               9.0        154      5000       19   \n",
      "3         mpfi  3.19    3.40              10.0        102      5500       24   \n",
      "4         mpfi  3.19    3.40               8.0        115      5500       18   \n",
      "\n",
      "  highway_mpg  price  \n",
      "0          27  13495  \n",
      "1          27  16500  \n",
      "2          26  16500  \n",
      "3          30  13950  \n",
      "4          22  17450  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cols = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "        \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
    "        \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
    "        \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
    "        \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "data = pd.read_csv(\"imports-85.data.csv\", names=cols)\n",
    "\n",
    "data.replace(\"?\", np.nan, inplace=True)\n",
    "\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a36fe",
   "metadata": {},
   "source": [
    "2       \n",
    " Replace all NaN values with central tendency imputation. Drop the rows with NaN  \n",
    "values in price column  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e10eeead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows after cleaning: (205, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_6788\\3652963809.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mean(), inplace=True)\n",
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_6788\\3652963809.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = [\"symboling\", \"normalized_losses\", \"wheel_base\", \"length\", \"width\", \n",
    "                \"height\", \"curb_weight\", \"engine_size\", \"bore\", \"stroke\",\n",
    "                \"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "categorical_cols = list(set(cols) - set(numeric_cols))\n",
    "for col in categorical_cols:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "\n",
    "data = data.dropna(subset=[\"price\"])\n",
    "\n",
    "print(\"Remaining rows after cleaning:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564915a1",
   "metadata": {},
   "source": [
    "3          \n",
    " There are 10 columns in the dataset with non-numeric values. Convert these values to  \n",
    "numeric values using following scheme:  \n",
    "(i) For ‚Äúnum_doors‚Äù and ‚Äúnum_cylinders‚Äù: convert words (number names) to figures  \n",
    "for e.g., two to 2  \n",
    "(ii) For \"body_style\", \"drive_wheels\": use dummy encoding scheme  \n",
    "(iii) For ‚Äúmake‚Äù, ‚Äúaspiration‚Äù, ‚Äúengine_location‚Äù,fuel_type: use label encoding  \n",
    "scheme  \n",
    "(iv) For fuel_system: replace values containing string pfi to 1 else all values to 0.  \n",
    "(v) For engine_type: replace values containing string ohc to 1 else all values to 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8c09308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after encoding:\n",
      "    symboling  normalized_losses  make  fuel_type  aspiration  num_doors  \\\n",
      "0          3              122.0     0          1           0          2   \n",
      "1          3              122.0     0          1           0          2   \n",
      "2          1              122.0     0          1           0          2   \n",
      "3          2              164.0     1          1           0          4   \n",
      "4          2              164.0     1          1           0          4   \n",
      "\n",
      "   engine_location  wheel_base  length  width  ...  peak_rpm  city_mpg  \\\n",
      "0                0        88.6   168.8   64.1  ...    5000.0        21   \n",
      "1                0        88.6   168.8   64.1  ...    5000.0        21   \n",
      "2                0        94.5   171.2   65.5  ...    5000.0        19   \n",
      "3                0        99.8   176.6   66.2  ...    5500.0        24   \n",
      "4                0        99.4   176.6   66.4  ...    5500.0        18   \n",
      "\n",
      "   highway_mpg    price  body_style_hardtop  body_style_hatchback  \\\n",
      "0           27  13495.0               False                 False   \n",
      "1           27  16500.0               False                 False   \n",
      "2           26  16500.0               False                  True   \n",
      "3           30  13950.0               False                 False   \n",
      "4           22  17450.0               False                 False   \n",
      "\n",
      "   body_style_sedan  body_style_wagon  drive_wheels_fwd  drive_wheels_rwd  \n",
      "0             False             False             False              True  \n",
      "1             False             False             False              True  \n",
      "2             False             False             False              True  \n",
      "3              True             False              True             False  \n",
      "4              True             False             False             False  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_6788\\3998969858.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"num_doors\"] = data[\"num_doors\"].replace(num_map).astype(int)\n",
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_6788\\3998969858.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"num_cylinders\"] = data[\"num_cylinders\"].replace(num_map).astype(int)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_map = {\n",
    "    \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "    \"six\": 6, \"eight\": 8, \"twelve\": 12\n",
    "}\n",
    "data[\"num_doors\"] = data[\"num_doors\"].replace(num_map).astype(int)\n",
    "data[\"num_cylinders\"] = data[\"num_cylinders\"].replace(num_map).astype(int)\n",
    "\n",
    "data = pd.get_dummies(data, columns=[\"body_style\", \"drive_wheels\"], drop_first=True)\n",
    "\n",
    "label_enc_cols = [\"make\", \"aspiration\", \"engine_location\", \"fuel_type\"]\n",
    "le = LabelEncoder()\n",
    "for col in label_enc_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "data[\"fuel_system\"] = data[\"fuel_system\"].apply(lambda x: 1 if \"pfi\" in x else 0)\n",
    "data[\"engine_type\"] = data[\"engine_type\"].apply(lambda x: 1 if \"ohc\" in x else 0)\n",
    "\n",
    "print(\"Dataset after encoding:\\n\", data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d04488",
   "metadata": {},
   "source": [
    "\n",
    "4    \n",
    "Divide the dataset into input features (all columns except price) and output variable  \n",
    "(price). Scale all input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f38ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (205, 29) y shape: (205,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=[\"price\"]).values\n",
    "y = data[\"price\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"X shape:\", X_scaled.shape, \"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc407b5",
   "metadata": {},
   "source": [
    "  \n",
    "5          \n",
    " Train a linear regressor on 70% of data (using inbuilt linear regression function of  \n",
    "Python) and test its performance on remaining 30% of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228d7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R2 score: 0.8044422435762588\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression R2 score:\", r2_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
